{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain M3GNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pol Benítez Colominas, March 2024\n",
    "# Universitat Politècnica de Catalunya\n",
    "\n",
    "# Script to re-train M3GNet from the dataset created with DFT data\n",
    "# IMPORTANT: this code is based in the code developed by Cibrán: https://github.com/CibranLopez/m3gnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from pymatgen.io.vasp.outputs import Vasprun\n",
    "from pymatgen.core.structure import Structure\n",
    "\n",
    "import matgl\n",
    "from matgl.ext.pymatgen import Structure2Graph, get_element_list\n",
    "from matgl.graph.data import M3GNetDataset, MGLDataLoader, collate_fn_efs\n",
    "from matgl.utils.training import PotentialLightningModule\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define materials with DFT data, here, we have a directory of data, that contains folders for each of the materials, and for each material contains a different number of folders with vasprun.xml files, for example: data_training/Ag3SCl/01/vasprun.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#materials = ['Ag3SCl', 'Ag3SBr', 'Ag3SI', 'Ag3SeCl', 'Ag3SeBr', 'Ag3SeI', \n",
    "#             'Cu3SCl', 'Cu3SBr', 'Cu3SI', 'Cu3SeCl', 'Cu3SeBr', 'Cu3SeI']\n",
    "\n",
    "materials = ['Ag3SeBr']\n",
    "\n",
    "data_path = 'data_training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save six features for each ionic step, the material, the phase, the structure, the energy, the forces and the stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_name = []\n",
    "phase_number = []\n",
    "structures = []\n",
    "energies = []\n",
    "forces = []\n",
    "stresses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a file where we store the number of data rows (accumulated) for each material\n",
    "info_data = open('info_data.txt', 'w')\n",
    "info_data.write('Material   #rows\\n')\n",
    "num_rows = 0\n",
    "\n",
    "# run for each material\n",
    "for mat in materials:\n",
    "    phases = [d for d in os.listdir(data_path + mat) if os.path.isdir(os.path.join(data_path + mat, d))]\n",
    "\n",
    "    # run for each phase of the given material\n",
    "    for phase in phases:\n",
    "        try:\n",
    "            vasprun = Vasprun(data_path + mat + '/' + phase + '/vasprun.xml', exception_on_bad_xml=False)\n",
    "        except:\n",
    "            print('Error: vasprun not correctly loaded.')\n",
    "            continue\n",
    "\n",
    "        # save the desired features for each ionic step of each phase of the given material\n",
    "        for step in vasprun.ionic_steps:\n",
    "            material_name.append(mat)\n",
    "            phase_number.append(phase)\n",
    "            structures.append(step['structure'])\n",
    "            energies.append(step['electronic_steps'][-1]['e_fr_energy'])\n",
    "            forces.append(step['forces'])\n",
    "            stresses.append(step['stress'])\n",
    "\n",
    "            num_rows = num_rows + 1\n",
    "    \n",
    "    info_data.write(f'{mat}   {num_rows:06d}\\n')\n",
    "\n",
    "info_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'material': material_name,\n",
    "    'phase': phase_number,\n",
    "    'structure': structures,\n",
    "    'energy': energies,\n",
    "    'force': forces,\n",
    "    'stress': stresses\n",
    "}\n",
    "\n",
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all the different simulations, since all the ionic steps of one simulation should be in the same \n",
    "# train-validation-test set\n",
    "\n",
    "df_data['material_phase'] = df_data['material'] + '_' + df_data['phase']\n",
    "\n",
    "unique_elements = df_data['material_phase'].unique()\n",
    "unique_elements = np.array(unique_elements)\n",
    "np.random.shuffle(unique_elements)\n",
    "\n",
    "print(unique_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the desired proportions of data for train-validation-test, note that ass steps are grouped by\n",
    "# chunks of the same simulation, the final proportions may be slightly different\n",
    "train_prop = 0.7\n",
    "val_prop = 0.15\n",
    "test_prop = 0.15\n",
    "\n",
    "train_set = pd.DataFrame(columns=df_data.columns)\n",
    "validation_set = pd.DataFrame(columns=df_data.columns)\n",
    "test_set = pd.DataFrame(columns=df_data.columns)\n",
    "\n",
    "total_rows = len(df_data)\n",
    "num_rows = 0\n",
    "for element in unique_elements:\n",
    "    if (num_rows/total_rows) <= train_prop:\n",
    "        new_elements = df_data[df_data['material_phase'] == element]\n",
    "\n",
    "        train_set = pd.concat([train_set, new_elements], ignore_index=True)\n",
    "\n",
    "        num_rows = len(train_set)\n",
    "    elif ((num_rows/total_rows) > train_prop) and ((num_rows/total_rows) <= (val_prop + train_prop)):\n",
    "        new_elements = df_data[df_data['material_phase'] == element]\n",
    "\n",
    "        validation_set = pd.concat([validation_set, new_elements], ignore_index=True)\n",
    "\n",
    "        num_rows = len(train_set) + len(validation_set)\n",
    "    elif (num_rows/total_rows) > (val_prop + train_prop):\n",
    "        new_elements = df_data[df_data['material_phase'] == element]\n",
    "\n",
    "        test_set = pd.concat([test_set, new_elements], ignore_index=True)\n",
    "\n",
    "        num_rows = len(train_set) + len(validation_set) + len(test_set)\n",
    "\n",
    "n_test       = len(test_set)\n",
    "n_validation = len(validation_set)\n",
    "n_train      = len(train_set)\n",
    "\n",
    "print(f'Using {n_train} samples to train, {n_validation} to evaluate, and {n_test} to test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into graphs and define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_path = 'M3GNet-MP-2021.2.8-PES'\n",
    "model_save_path = 'finetuned_model'\n",
    "\n",
    "stress_weight = 0 # consider stresses or not\n",
    "batch_size = 128\n",
    "max_epochs = 50\n",
    "lr = 1e-4 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for i in range(3):  # Iterate over train-validation-test sets\n",
    "    name    = ['train', 'val', 'test'][i]\n",
    "    dataset = [train_set, validation_set, test_set][i]\n",
    "\n",
    "    # extract data from dataset\n",
    "    structures = dataset.loc[:,'structure'].values.tolist()\n",
    "    element_types = get_element_list(structures)\n",
    "    converter = Structure2Graph(element_types=element_types, cutoff=5.0)\n",
    "\n",
    "    # define data labels from dataset\n",
    "    if stress_weight == 0:\n",
    "        stresses = [np.zeros((3, 3)).tolist() for s in structures]\n",
    "    else:\n",
    "        stresses = dataset.loc[:,'stress'].values.tolist()\n",
    "\n",
    "    labels = {\n",
    "        'energies': dataset.loc[:,'energy'].values.tolist(),\n",
    "        'forces':   dataset.loc[:,'force'].values.tolist(),\n",
    "        'stresses': stresses,\n",
    "    }\n",
    "\n",
    "    # generate dataset\n",
    "    data = M3GNetDataset(\n",
    "        filename=f'dgl_graph-{name}.bin',\n",
    "        filename_line_graph=f'dgl_line_graph-{name}.bin',\n",
    "        filename_state_attr=f'state_attr-{name}.pt',\n",
    "        filename_labels=f'labels-{name}.json',\n",
    "        threebody_cutoff=4.0,\n",
    "        structures=structures,\n",
    "        converter=converter,\n",
    "        labels=labels,\n",
    "        name=f'M3GNetDataset-{name}',\n",
    "    )\n",
    "    all_data.append(data)\n",
    "\n",
    "train_data, val_data, test_data = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = MGLDataLoader(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    collate_fn=collate_fn_efs,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3gnet_nnp       = matgl.load_model(model_load_path)\n",
    "model_pretrained = m3gnet_nnp.model\n",
    "\n",
    "lit_module_finetune = PotentialLightningModule(model=model_pretrained,\n",
    "                                               stress_weight=stress_weight,\n",
    "                                               loss='mse_loss', \n",
    "                                               lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger  = CSVLogger('logs', \n",
    "                    name='M3GNet_finetuning')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, \n",
    "                     accelerator='auto', \n",
    "                     logger=logger, \n",
    "                     inference_mode=False)\n",
    "\n",
    "trainer.fit(model=lit_module_finetune, \n",
    "            train_dataloaders=train_loader, \n",
    "            val_dataloaders=val_loader)\n",
    "\n",
    "# Save trained model\n",
    "model_pretrained.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E_MAE = meV/atom, F_MAE = eV/A, S_MAE = GPa\n",
    "trainer.test(model=lit_module_finetune,\n",
    "            dataloaders=test_loader\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "current_version = 0\n",
    "path_to_csv = f'logs/M3GNet_finetuning/version_{current_version}'\n",
    "df = pd.read_csv(f'{path_to_csv}/metrics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN to zero\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Calculate the sum of every two consecutive rows\n",
    "df = df.groupby(df.index // 2).sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of loss column names\n",
    "loss_columns = [col for col in df.columns if col.startswith('val_') or col.startswith('train_')]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot each loss\n",
    "for loss_column in loss_columns:\n",
    "    plt.plot(df.index, np.log(df[loss_column]), label=loss_column)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=(1.01, 0))\n",
    "plt.savefig(f'm3gnet_loss.eps', dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code just performs cleanup for this notebook from temporal files\n",
    "\n",
    "patterns = ['dgl_graph*.bin', 'dgl_line_graph*.bin', 'state_attr*.pt', 'labels*.json', '*labels.txt']\n",
    "for pattern in patterns:\n",
    "    files = glob.glob(pattern)\n",
    "    for file in files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "shutil.rmtree('logs')\n",
    "#shutil.rmtree('trained_model')\n",
    "#shutil.rmtree('finetuned_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
